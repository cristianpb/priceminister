{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my method from the source code\n",
    "%aimport data.read_data\n",
    "%aimport models.train_model\n",
    "%aimport models.predict_model\n",
    "%aimport features.build_features\n",
    "%aimport visualization.visualize\n",
    "from data.read_data import read_data, get_stopwords\n",
    "from models.train_model import split_train, score_function, model_ridge, model_xgb, model_ensembler\n",
    "from models.predict_model import predict_test\n",
    "from features.build_features import feature_extraction\n",
    "from visualization.visualize import plot_roc, plot_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = read_data(test=True)\n",
    "nrow_train = train.shape[0]\n",
    "y = train['Target']\n",
    "merge: pd.DataFrame = pd.concat([train, test])\n",
    "submission: pd.DataFrame = test['ID']\n",
    "\n",
    "del train\n",
    "del test\n",
    "gc.collect()\n",
    "\n",
    "stopwords = get_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:23] INFO loading projection weights from ../data/external/wiki.fr.bin\n",
      "[23:43:23] DEBUG {'kw': {}, 'mode': 'rb', 'uri': '../data/external/wiki.fr.bin'}\n",
      "[23:43:23] DEBUG encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='../data/external/wiki.fr.bin'>}\n",
      "[23:43:45] INFO loaded (1152449, 300) matrix from ../data/external/wiki.fr.bin\n"
     ]
    }
   ],
   "source": [
    "merge_sparse, merge_ft = feature_extraction(merge, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sparse = merge_sparse[:nrow_train]\n",
    "X_ft = merge_ft[:nrow_train]\n",
    "X_test_sparse = merge_sparse[nrow_train:]\n",
    "X_test_ft = merge_ft[nrow_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:00] INFO Found 2 classes\n",
      "[23:45:00] INFO Training Level 0 Fold # 1. Model # 0\n",
      "[23:47:19] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[23:47:20] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.718949\n",
      "[23:47:20] INFO Training Level 0 Fold # 2. Model # 0\n",
      "[23:49:37] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[23:49:38] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.716949\n",
      "[23:49:38] INFO Training Level 0 Fold # 3. Model # 0\n",
      "[23:51:50] INFO Predicting Level 0. Fold # 3. Model # 0\n",
      "[23:51:51] INFO Level 0. Fold # 3. Model # 0. Validation Score = 0.714180\n",
      "[23:51:51] INFO Level 0. Model # 0. Mean Score = 0.716693. Std Dev = 0.001955\n",
      "[23:51:51] INFO Training Level 0 Fold # 1. Model # 1\n",
      "[23:52:31] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[23:52:34] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.714212\n",
      "[23:52:34] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[23:53:14] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[23:53:19] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.709963\n",
      "[23:53:19] INFO Training Level 0 Fold # 3. Model # 1\n",
      "[23:53:59] INFO Predicting Level 0. Fold # 3. Model # 1\n",
      "[23:54:02] INFO Level 0. Fold # 3. Model # 1. Validation Score = 0.711833\n",
      "[23:54:02] INFO Level 0. Model # 1. Mean Score = 0.712003. Std Dev = 0.001739\n",
      "[23:54:02] INFO Saving predictions for level # 0\n",
      "[23:54:03] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[23:54:06] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[23:54:07] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.712046\n",
      "[23:54:07] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[23:54:10] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[23:54:10] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.710176\n",
      "[23:54:10] INFO Training Level 1 Fold # 3. Model # 0\n",
      "[23:54:14] INFO Predicting Level 1. Fold # 3. Model # 0\n",
      "[23:54:14] INFO Level 1. Fold # 3. Model # 0. Validation Score = 0.707368\n",
      "[23:54:14] INFO Level 1. Model # 0. Mean Score = 0.709863. Std Dev = 0.001923\n",
      "[23:54:14] INFO Saving predictions for level # 1\n"
     ]
    }
   ],
   "source": [
    "ens = model_ensembler(X_sparse, X_ft, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/cris/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[23:54:21] INFO Training Fulldata Level 0. Model # 0\n",
      "[23:57:12] INFO Predicting Test Level 0. Model # 0\n",
      "[23:57:13] INFO Training Fulldata Level 0. Model # 1\n",
      "[23:58:12] INFO Predicting Test Level 0. Model # 1\n",
      "[23:58:16] INFO Training Fulldata Level 1. Model # 0\n",
      "[23:58:21] INFO Predicting Test Level 1. Model # 0\n"
     ]
    }
   ],
   "source": [
    "test_data_dict = {0: [X_test_sparse, X_test_sparse], 1: [X_test_ft]}\n",
    "preds = ens.predict(test_data_dict, lentest=X_test_ft.shape[0])\n",
    "preds1 = np.mean((preds[0][:,1], preds[1][:,1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85922089,  0.00883833,  0.23765411, ...,  0.15293477,\n",
       "        0.22380195,  0.69110957])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test(submission,preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../models/submission_18-01-07.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = df['Target'].apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../models/submission_1.csv',                                                                                                        \n",
    "                      index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.read_csv('../data/raw/challenge_fichier_de_sortie_dentrainement_prediction_de_linteret_des_avis_utilisateurs.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = real.iloc[59999:79999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49455470902111398"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_function(df_tmp['Target'], submission['Target'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdiscount kernel",
   "language": "python",
   "name": "cdiscount"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
